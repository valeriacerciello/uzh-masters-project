{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "116382bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Data path: Expert_data/expert_data_rllib_simple_push.pickle\n"
     ]
    }
   ],
   "source": [
    "#Imports & hyperparameters\n",
    "\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Training device\n",
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Path to expert trajectories (simple_push)\n",
    "data_path  = \"Expert_data/expert_data_rllib_simple_push.pickle\"\n",
    "\n",
    "# BC hyperparameters\n",
    "batch_size = 64\n",
    "lr         = 1e-3\n",
    "epochs     = 50\n",
    "hidden_dim = 64\n",
    "\n",
    "print(\"Device:\", device)\n",
    "print(\"Data path:\", data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca6f47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expert_data type: <class 'dict'>\n",
      "Agents available: ['adversary_0', 'agent_0']\n",
      "  adversary_0: 1200 transitions, state shape=(8,), action shape=()\n",
      "  agent_0: 1200 transitions, state shape=(19,), action shape=()\n"
     ]
    }
   ],
   "source": [
    "# Load & inspect expert_data\n",
    "# Load the pickled expert trajectories\n",
    "with open(data_path, \"rb\") as f:\n",
    "    expert_data = pickle.load(f)\n",
    "\n",
    "# Sanity check\n",
    "print(\"expert_data type:\", type(expert_data))\n",
    "print(\"Agents available:\", list(expert_data.keys()))\n",
    "\n",
    "# For each agent, print number of transitions and example shapes\n",
    "for agent, data in expert_data.items():\n",
    "    n_states  = len(data[\"states\"])\n",
    "    n_actions = len(data[\"actions\"])\n",
    "    # Peek at shapes\n",
    "    state_shape  = np.array(data[\"states\"][0]).shape\n",
    "    action_shape = np.array(data[\"actions\"][0]).shape\n",
    "    print(f\"  {agent}: {n_states} transitions, state shape={state_shape}, action shape={action_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70549eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adversary_0 batch shapes → states: torch.Size([64, 8]), actions: torch.Size([64])\n",
      "agent_0 batch shapes → states: torch.Size([64, 19]), actions: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# SingleAgentExpertDataset + DataLoaders\n",
    "class SingleAgentExpertDataset(Dataset):\n",
    "    def __init__(self, states, actions):\n",
    "        # Convert lists of numpy arrays into torch tensors\n",
    "        self.states  = torch.from_numpy(np.array(states)).float()\n",
    "        self.actions = torch.from_numpy(np.array(actions)).long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.states)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.states[idx], self.actions[idx]\n",
    "\n",
    "# Instantiate datasets and loaders\n",
    "datasets = {}\n",
    "loaders  = {}\n",
    "\n",
    "for agent, data in expert_data.items():\n",
    "    ds     = SingleAgentExpertDataset(data[\"states\"], data[\"actions\"])\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "    datasets[agent] = ds\n",
    "    loaders[agent]  = loader\n",
    "\n",
    "    # Print a batch shape for sanity\n",
    "    s_batch, a_batch = next(iter(loader))\n",
    "    print(f\"{agent} batch shapes → states: {s_batch.shape}, actions: {a_batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34fcfc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adversary_0 policy → obs_dim: 8, act_dim: 5\n",
      "BCPolicy(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=5, bias=True)\n",
      "  )\n",
      ")\n",
      "agent_0 policy → obs_dim: 19, act_dim: 5\n",
      "BCPolicy(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=19, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Behavior Cloning policy network definition\n",
    "import torch.nn as nn\n",
    "\n",
    "class BCPolicy(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, act_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Instantiate one BCPolicy per agent\n",
    "policies = {}\n",
    "for agent, ds in datasets.items():\n",
    "    obs_dim = ds.states.shape[1]\n",
    "    # assume actions are 0...act_dim-1\n",
    "    act_dim = int(ds.actions.max().item()) + 1\n",
    "    policy = BCPolicy(obs_dim, act_dim, hidden_dim).to(device)\n",
    "    policies[agent] = policy\n",
    "    print(f\"{agent} policy → obs_dim: {obs_dim}, act_dim: {act_dim}\")\n",
    "    print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32abc797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training BC policy for adversary_0 ===\n",
      "adversary_0  Epoch  1/50: loss = 1.5626\n",
      "adversary_0  Epoch 10/50: loss = 0.9564\n",
      "adversary_0  Epoch 20/50: loss = 0.7226\n",
      "adversary_0  Epoch 30/50: loss = 0.6269\n",
      "adversary_0  Epoch 40/50: loss = 0.5666\n",
      "adversary_0  Epoch 50/50: loss = 0.5109\n",
      "\n",
      "=== Training BC policy for agent_0 ===\n",
      "agent_0  Epoch  1/50: loss = 1.5674\n",
      "agent_0  Epoch 10/50: loss = 1.0059\n",
      "agent_0  Epoch 20/50: loss = 0.5708\n",
      "agent_0  Epoch 30/50: loss = 0.3979\n",
      "agent_0  Epoch 40/50: loss = 0.3105\n",
      "agent_0  Epoch 50/50: loss = 0.2616\n"
     ]
    }
   ],
   "source": [
    "# train each agent’s BCPolicy via supervised learning\n",
    "import torch.nn as nn\n",
    "\n",
    "# Set up optimizers and loss\n",
    "optimizers = {\n",
    "    agent: torch.optim.Adam(policy.parameters(), lr=lr)\n",
    "    for agent, policy in policies.items()\n",
    "}\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "for agent in policies:\n",
    "    print(f\"\\n=== Training BC policy for {agent} ===\")\n",
    "    policy    = policies[agent]\n",
    "    optimizer = optimizers[agent]\n",
    "    loader    = loaders[agent]\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        total_loss = 0.0\n",
    "        for states, actions in loader:\n",
    "            states, actions = states.to(device), actions.to(device)\n",
    "            logits = policy(states)\n",
    "            loss   = loss_fn(logits, actions)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(loader)\n",
    "        # Print every 10 epochs (and first epoch)\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print(f\"{agent}  Epoch {epoch:>2}/{epochs}: loss = {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecf9df8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved adversary_0 policy to bc_adversary_0.pt\n",
      "Saved agent_0 policy to bc_agent_0.pt\n",
      "Reloaded adversary_0 policy from bc_adversary_0.pt successfully.\n",
      "Reloaded agent_0 policy from bc_agent_0.pt successfully.\n"
     ]
    }
   ],
   "source": [
    "# save and reload BC policy checkpoints\n",
    "model_paths = {}\n",
    "\n",
    "for agent, policy in policies.items():\n",
    "    path = f\"bc_{agent}.pt\"\n",
    "    torch.save(policy.state_dict(), path)\n",
    "    model_paths[agent] = path\n",
    "    print(f\"Saved {agent} policy to {path}\")\n",
    "\n",
    "# Reload to verify\n",
    "for agent, path in model_paths.items():\n",
    "    obs_dim = datasets[agent].states.shape[1]\n",
    "    act_dim = int(datasets[agent].actions.max().item()) + 1\n",
    "    # recreate the model\n",
    "    check_policy = BCPolicy(obs_dim, act_dim, hidden_dim).to(device)\n",
    "    check_policy.load_state_dict(torch.load(path))\n",
    "    check_policy.eval()\n",
    "    print(f\"Reloaded {agent} policy from {path} successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf8dbe73",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "PettingZoo (and its pygame dependency) is required for evaluation. On macOS: `brew install sdl2 sdl2_image sdl2_ttf sdl2_mixer` then `pip install pygame pettingzoo`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpettingzoo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmpe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m simple_push_v3\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.2/lib/python3.13/site-packages/pettingzoo/mpe/__init__.py:5\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(env_name)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(env_name):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeprecated_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__path__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.2/lib/python3.13/site-packages/pettingzoo/utils/deprecated_module.py:60\u001b[39m, in \u001b[36mdeprecated_handler\u001b[39m\u001b[34m(env_name, module_path, module_name)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m spec.loader\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[43mspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexec_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.2/lib/python3.13/site-packages/pettingzoo/mpe/simple_push_v3.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpettingzoo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmpe\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msimple_push\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msimple_push\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m env, parallel_env, raw_env\n\u001b[32m      3\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33menv\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mparallel_env\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mraw_env\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.2/lib/python3.13/site-packages/pettingzoo/mpe/simple_push/simple_push.py:55\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpettingzoo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmpe\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_mpe_utils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mscenario\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseScenario\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpettingzoo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmpe\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_mpe_utils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msimple_env\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SimpleEnv, make_env\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpettingzoo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconversions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parallel_wrapper_fn\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.2/lib/python3.13/site-packages/pettingzoo/mpe/_mpe_utils/simple_env.py:5\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpygame\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgymnasium\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m spaces\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pygame'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpettingzoo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmpe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m simple_push_v3\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m      6\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPettingZoo (and its pygame dependency) is required for evaluation. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOn macOS: `brew install sdl2 sdl2_image sdl2_ttf sdl2_mixer` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthen `pip install pygame pettingzoo`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m     )\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate_bc_agents\u001b[39m(policies, num_episodes=\u001b[32m20\u001b[39m):\n\u001b[32m     12\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[33;03m    Evaluate BC policies for each agent in simple_push.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: PettingZoo (and its pygame dependency) is required for evaluation. On macOS: `brew install sdl2 sdl2_image sdl2_ttf sdl2_mixer` then `pip install pygame pettingzoo`."
     ]
    }
   ],
   "source": [
    "# Evaluation stub for BC policies\n",
    "try:\n",
    "    from pettingzoo.mpe import simple_push_v3\n",
    "except ImportError:\n",
    "    raise ImportError(\n",
    "        \"PettingZoo (and its pygame dependency) is required for evaluation. \"\n",
    "        \"On macOS: `brew install sdl2 sdl2_image sdl2_ttf sdl2_mixer` \"\n",
    "        \"then `pip install pygame pettingzoo`.\"\n",
    "    )\n",
    "\n",
    "def evaluate_bc_agents(policies, num_episodes=20):\n",
    "    \"\"\"\n",
    "    Evaluate BC policies for each agent in simple_push.\n",
    "    \"\"\"\n",
    "    env = simple_push_v3.parallel_env(continuous_actions=True, max_cycles=25)\n",
    "    returns = {agent: [] for agent in env.agents}\n",
    "\n",
    "    for ep in range(num_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        done = {a: False for a in env.agents}\n",
    "        ep_rewards = {a: 0.0 for a in env.agents}\n",
    "\n",
    "        while not all(done.values()):\n",
    "            actions = {}\n",
    "            for agent in env.agents:\n",
    "                state = torch.from_numpy(obs[agent]).float().to(device)\n",
    "                logits = policies[agent](state)\n",
    "                actions[agent] = torch.argmax(logits).item()\n",
    "            obs, rewards, terminations, truncations, _ = env.step(actions)\n",
    "            for agent in env.agents:\n",
    "                ep_rewards[agent] += rewards.get(agent, 0)\n",
    "            done = {\n",
    "                a: terminations.get(a, False) or truncations.get(a, False)\n",
    "                for a in env.agents\n",
    "            }\n",
    "\n",
    "        for agent in env.agents:\n",
    "            returns[agent].append(ep_rewards[agent])\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    # Print average returns\n",
    "    for agent, vals in returns.items():\n",
    "        avg_ret = sum(vals) / len(vals)\n",
    "        print(f\"{agent} BC avg return over {num_episodes} eps: {avg_ret:.2f}\")\n",
    "\n",
    "# Run evaluation\n",
    "evaluate_bc_agents(policies, num_episodes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "428f1718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Held-out expert classification accuracy per agent:\n",
      "  adversary_0: 87.00%\n",
      "  agent_0: 91.50%\n"
     ]
    }
   ],
   "source": [
    "# Held-out Expert Accuracy (no env needed)\n",
    "# Install scikit-learn if missing\n",
    "import sys\n",
    "try:\n",
    "    from sklearn.metrics import accuracy_score\n",
    "except ImportError:\n",
    "    !{sys.executable} -m pip install scikit-learn\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Held-out expert classification accuracy per agent:\")\n",
    "\n",
    "# Use the last 200 samples as a “test” split\n",
    "n_test = 200\n",
    "\n",
    "for agent, ds in datasets.items():\n",
    "    states  = ds.states.cpu().numpy()\n",
    "    actions = ds.actions.cpu().numpy()\n",
    "\n",
    "    test_states  = torch.from_numpy(states[-n_test:]).to(device)\n",
    "    test_actions = actions[-n_test:]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = policies[agent](test_states)\n",
    "        preds  = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "\n",
    "    acc = accuracy_score(test_actions, preds)\n",
    "    print(f\"  {agent}: {acc*100:5.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
