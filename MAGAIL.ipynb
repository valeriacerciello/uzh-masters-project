{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agents: ['speaker_0', 'listener_0']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from pettingzoo.mpe import simple_speaker_listener_v4\n",
    "\n",
    "def make_env():\n",
    "    env = simple_speaker_listener_v4.parallel_env(continuous_actions=False, render_mode=\"rgb_array\", max_cycles=25)\n",
    "    env.reset()\n",
    "    return env\n",
    "\n",
    "def make_env_human():\n",
    "    env = simple_speaker_listener_v4.parallel_env(continuous_actions=False, render_mode=\"human\", max_cycles=25)\n",
    "    env.reset()\n",
    "    return env\n",
    "\n",
    "# Test the environment\n",
    "env = make_env()\n",
    "print(\"Agents:\", env.agents)  # ['speaker_0', 'listener_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Policy Networks (one per agent)\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, act_dim),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Discriminator Networks (one per agent)\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_dim + act_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid())\n",
    "    \n",
    "    def forward(self, state, action):\n",
    "        return self.net(torch.cat([state, action], dim=-1))\n",
    "    \n",
    "# Value Network as baseline\n",
    "class ValueNet(nn.Module):\n",
    "    def __init__(self, obs_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# Initialize policies and discriminators\n",
    "\n",
    "speaker_obs_dim = 3     #[goal_id]\n",
    "listener_obs_dim = 11 #[self_vel, all_landmark_rel_positions, communication]\n",
    "\n",
    "speaker_act_dim = 3 # [say_0, say_1, say_2, say_3, say_4, say_5, say_6, say_7, say_8, say_9]\n",
    "listener_act_dim = 5 # [no_action, move_left, move_right, move_down, move_up]\n",
    "\n",
    "policies = {\n",
    "    \"speaker_0\": Policy(obs_dim=speaker_obs_dim, act_dim=speaker_act_dim),  \n",
    "    \"listener_0\": Policy(obs_dim=listener_obs_dim, act_dim=listener_act_dim)   \n",
    "}\n",
    "\n",
    "# For Discriminator the output is a single value\n",
    "discriminators = {\n",
    "    \"speaker_0\": Discriminator(obs_dim=3, act_dim=3),   # Speaker: 3 obs + 3 actions\n",
    "    \"listener_0\": Discriminator(obs_dim=11, act_dim=5)  # Listener: 11 obs + 5 actions\n",
    "}\n",
    "\n",
    "# Initialize value networks\n",
    "value_nets = {\n",
    "    \"speaker_0\": ValueNet(obs_dim=speaker_obs_dim),\n",
    "    \"listener_0\": ValueNet(obs_dim=listener_obs_dim)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expert Demonstrations\n",
    "For simplicity, we use a heuristic expert - but this is not good...\n",
    "\n",
    "We shall use pre-trained expert policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = simple_speaker_listener_v4.parallel_env(max_cycles=25, continuous_actions=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved h_dim: 128\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the expert policy\n",
    "expert_policies = torch.jit.load(\"Expert_data/simple_speaker_listener.pt\").to(device)\n",
    "expert_policies.eval()\n",
    "\n",
    "# Try to retrieve h_dim from the policy, fallback to 128\n",
    "try:\n",
    "    h_dim = expert_policies.h_dim\n",
    "    print(f\"Retrieved h_dim: {h_dim}\")\n",
    "except AttributeError:\n",
    "    h_dim = 128  # From error message\n",
    "    print(\"h_dim not accessible, using 128\")\n",
    "\n",
    "def expert_policy(obs, rnn_actor, deterministic=True):\n",
    "    with torch.no_grad():\n",
    "        # Convert observations to tensors\n",
    "        obs_speaker = torch.FloatTensor(obs[\"speaker_0\"]).to(device)\n",
    "        obs_listener = torch.FloatTensor(obs[\"listener_0\"]).to(device)\n",
    "        # Pad speaker's observation (3) to match listenerâ€™s (11)\n",
    "        obs_speaker_padded = torch.nn.functional.pad(obs_speaker, (0, 11 - 3))\n",
    "        obs_batch = torch.stack([obs_speaker_padded, obs_listener], dim=0)\n",
    "        \n",
    "        # Define masks and available actions\n",
    "        masks = torch.ones((2, 1), dtype=torch.bool, device=device)  # For 2 agents\n",
    "        avails = torch.ones((2, 5), dtype=torch.float32, device=device)  # Assuming 5 actions per agent\n",
    "        \n",
    "        # Forward pass through the policy\n",
    "        actions, _, new_rnn_actor = expert_policies._forward(\n",
    "            obs_batch, rnn_actor, masks, avails, deterministic\n",
    "        )\n",
    "        actions_dict = {\n",
    "            \"speaker_0\": actions[0].item(),\n",
    "            \"listener_0\": actions[1].item()\n",
    "        }\n",
    "        return actions_dict, new_rnn_actor\n",
    "\n",
    "def generate_expert_data(num_episodes=50):\n",
    "    env = make_env()  # Assuming this is defined elsewhere\n",
    "    expert_data = {agent: {\"states\": [], \"actions\": []} for agent in env.agents}\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        # Initialize rnn_actor with shape (n_agents, 1, h_dim) on device\n",
    "        rnn_actor = torch.zeros((2, 1, h_dim), device=device)\n",
    "\n",
    "        while not done:\n",
    "            actions, rnn_actor = expert_policy(obs, rnn_actor, deterministic=True)\n",
    "            for agent in env.agents:\n",
    "                expert_data[agent][\"states\"].append(obs[agent])\n",
    "                expert_data[agent][\"actions\"].append(actions[agent])\n",
    "            obs, _, done, _, _ = env.step(actions)\n",
    "\n",
    "    env.close()\n",
    "    return expert_data\n",
    "\n",
    "# Generate data\n",
    "expert_data = generate_expert_data(num_episodes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 Start: Listener = [0.         0.05140734], Goal = [0.4060055 0.       ], Goal Index = 1, Speaker Obs = [0.15 0.65 0.15]\n",
      "Step 1: Actions = {'speaker_0': 0, 'listener_0': 2}, Listener = [0.         0.05140734], Goal = [0.4060055 0.       ], Distance = 0.40924710035324097, Reward = -1.0345560408656842\n",
      "Step 2: Actions = {'speaker_0': 0, 'listener_0': 2}, Listener = [0.         0.00140734], Goal = [0.4060055 0.       ], Distance = 0.40600794553756714, Reward = -0.9159713189207666\n",
      "Step 3: Actions = {'speaker_0': 0, 'listener_0': 2}, Listener = [ 0.         -0.08609266], Goal = [0.4060055 0.       ], Distance = 0.4150330424308777, Reward = -0.7325105555171607\n",
      "Episode 0 End: Success = 0, Reward = -9.07259237228135, Steps = 26, Final Distance = 0.6569334864616394\n",
      "Episode 1 Start: Listener = [0.        0.6547794], Goal = [-0.42295668  0.        ], Goal Index = 1, Speaker Obs = [0.15 0.65 0.15]\n",
      "Step 1: Actions = {'speaker_0': 0, 'listener_0': 2}, Listener = [0.        0.6547794], Goal = [-0.42295668  0.        ], Distance = 0.77950519323349, Reward = -1.0013560275215476\n",
      "Step 2: Actions = {'speaker_0': 0, 'listener_0': 2}, Listener = [0.         0.60477936], Goal = [-0.42295668  0.        ], Distance = 0.7380043864250183, Reward = -0.9238168615236884\n",
      "Step 3: Actions = {'speaker_0': 0, 'listener_0': 2}, Listener = [0.        0.5172793], Goal = [-0.42295668  0.        ], Distance = 0.6681842803955078, Reward = -0.8121858210274345\n",
      "Episode 1 End: Success = 0, Reward = -17.381685099725, Steps = 26, Final Distance = 0.4938008189201355\n",
      "Expert Policy Evaluation: {'success_rate': np.float64(0.04), 'avg_reward': np.float64(-28.717905434976885), 'avg_steps': np.float64(26.0)}\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from pettingzoo.mpe import simple_speaker_listener_v4\n",
    "\n",
    "def evaluate_policy(policy_func, num_episodes=50, threshold=0.1, h_dim=128, device=device):\n",
    "    env = make_env()\n",
    "    success_rates = []\n",
    "    avg_rewards = []\n",
    "    avg_steps = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        speaker_obs = obs[\"speaker_0\"]\n",
    "        goal_index = np.argmax(speaker_obs)\n",
    "        done = {\"speaker_0\": False, \"listener_0\": False}\n",
    "        total_reward = 0\n",
    "        steps = 0\n",
    "        rnn_actor = torch.zeros((2, 1, h_dim), device=device)\n",
    "\n",
    "        # Compute fixed goal position at start\n",
    "        state = env.state()\n",
    "        listener_pos = state[4:6]\n",
    "        goal_pos = state[8 + 2 * goal_index : 10 + 2 * goal_index]  # Static landmark position\n",
    "\n",
    "        # Debug: Initial state\n",
    "        if episode < 2:\n",
    "            print(f\"Episode {episode} Start: Listener = {listener_pos}, Goal = {goal_pos}, Goal Index = {goal_index}, Speaker Obs = {speaker_obs}\")\n",
    "\n",
    "        while not all(done.values()):\n",
    "            actions, rnn_actor = policy_func(obs, rnn_actor, deterministic=True)\n",
    "            obs, rewards, done, _, _ = env.step(actions)\n",
    "            total_reward += sum(rewards.values())\n",
    "            steps += 1\n",
    "\n",
    "            # Compute current listener position\n",
    "            state = env.state()\n",
    "            listener_pos = state[4:6]\n",
    "            distance = np.linalg.norm(listener_pos - goal_pos)  # Use fixed goal_pos\n",
    "\n",
    "            # Debug: Step details\n",
    "            if episode < 2 and steps <= 3:\n",
    "                print(f\"Step {steps}: Actions = {actions}, Listener = {listener_pos}, Goal = {goal_pos}, Distance = {distance}, Reward = {sum(rewards.values())}\")\n",
    "\n",
    "        distance = np.linalg.norm(listener_pos - goal_pos)  # Final distance with fixed goal_pos\n",
    "        success = 1 if distance < threshold else 0\n",
    "\n",
    "        success_rates.append(success)\n",
    "        avg_rewards.append(total_reward)\n",
    "        avg_steps.append(steps)\n",
    "\n",
    "        if episode < 2:\n",
    "            print(f\"Episode {episode} End: Success = {success}, Reward = {total_reward}, Steps = {steps}, Final Distance = {distance}\")\n",
    "\n",
    "    env.close()\n",
    "    return {\n",
    "        \"success_rate\": np.mean(success_rates),\n",
    "        \"avg_reward\": np.mean(avg_rewards),\n",
    "        \"avg_steps\": np.mean(avg_steps)\n",
    "    }\n",
    "\n",
    "expert_eval = evaluate_policy(expert_policy, num_episodes=50)\n",
    "print(\"Expert Policy Evaluation:\", expert_eval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 Start: Listener = [0.         0.32962254], Goal = [0. 0.], Goal Index = 2, Speaker Obs = [0.15 0.15 0.65]\n",
      "Step 1: Actions = {'speaker_0': 2, 'listener_0': 2}, Listener = [0.         0.32962254], Goal = [0. 0.], Distance = 0.3296225368976593, Reward = -0.08006231832198152\n",
      "Step 2: Actions = {'speaker_0': 2, 'listener_0': 2}, Listener = [0.         0.27962255], Goal = [0. 0.], Distance = 0.27962255477905273, Reward = -0.0627826093451403\n",
      "Step 3: Actions = {'speaker_0': 2, 'listener_0': 1}, Listener = [0.         0.19212255], Goal = [0. 0.], Distance = 0.19212254881858826, Reward = -0.05660561863566819\n",
      "Episode 0 End: Success = 0, Reward = -1.5496400539216717, Steps = 26, Final Distance = 0.17915967106819153\n",
      "Episode 1 Start: Listener = [0.        1.2770889], Goal = [0.83463776 0.83238137], Goal Index = 0, Speaker Obs = [0.65 0.15 0.15]\n",
      "Step 1: Actions = {'speaker_0': 1, 'listener_0': 2}, Listener = [0.        1.2770889], Goal = [0.83463776 0.83238137], Distance = 0.9457192420959473, Reward = -3.363996797288314\n",
      "Step 2: Actions = {'speaker_0': 1, 'listener_0': 2}, Listener = [0.        1.2270889], Goal = [0.83463776 0.83238137], Distance = 0.9232628345489502, Reward = -3.1135790140636757\n",
      "Step 3: Actions = {'speaker_0': 1, 'listener_0': 2}, Listener = [0.       1.139589], Goal = [0.83463776 0.83238137], Distance = 0.8893799185752869, Reward = -2.699410393420559\n",
      "Episode 1 End: Success = 0, Reward = -17.30888985097046, Steps = 26, Final Distance = 1.2077715396881104\n",
      "Expert Policy Evaluation: {'success_rate': np.float64(0.04), 'avg_reward': np.float64(-40.956193981839185), 'avg_steps': np.float64(26.0)}\n"
     ]
    }
   ],
   "source": [
    "# Generate expert data and validate\n",
    "# expert_data = generate_expert_data(num_episodes=50)\n",
    "# Evaluate the expert policy\n",
    "expert_eval = evaluate_policy(expert_policy, num_episodes=50)\n",
    "print(\"Expert Policy Evaluation:\", expert_eval)\n",
    "# print(\"Expert Success Rate:\", expert_eval['success_rate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learned_policy(obs, _):\n",
    "    actions = {}\n",
    "    for agent in obs.keys():\n",
    "        obs_tensor = torch.FloatTensor(obs[agent])\n",
    "        action_probs = policies[agent](obs_tensor)\n",
    "        action = torch.argmax(action_probs).item()\n",
    "        actions[agent] = action\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MAGAIL Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Policy Networks (one per agent)\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, act_dim),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Discriminator Networks (one per agent)\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_dim + act_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid())\n",
    "    \n",
    "    def forward(self, state, action):\n",
    "        return self.net(torch.cat([state, action], dim=-1))\n",
    "    \n",
    "# Value Network as baseline\n",
    "class ValueNet(nn.Module):\n",
    "    def __init__(self, obs_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# Initialize policies and discriminators\n",
    "\n",
    "speaker_obs_dim = 3     #[goal_id]\n",
    "listener_obs_dim = 11 #[self_vel, all_landmark_rel_positions, communication]\n",
    "\n",
    "speaker_act_dim = 3 # [say_0, say_1, say_2, say_3, say_4, say_5, say_6, say_7, say_8, say_9]\n",
    "listener_act_dim = 5 # [no_action, move_left, move_right, move_down, move_up]\n",
    "\n",
    "policies = {\n",
    "    \"speaker_0\": Policy(obs_dim=speaker_obs_dim, act_dim=speaker_act_dim),  \n",
    "    \"listener_0\": Policy(obs_dim=listener_obs_dim, act_dim=listener_act_dim)   \n",
    "}\n",
    "\n",
    "# For Discriminator the output is a single value\n",
    "discriminators = {\n",
    "    \"speaker_0\": Discriminator(obs_dim=3, act_dim=3),   # Speaker: 3 obs + 3 actions\n",
    "    \"listener_0\": Discriminator(obs_dim=11, act_dim=5)  # Listener: 11 obs + 5 actions\n",
    "}\n",
    "\n",
    "# Initialize value networks\n",
    "value_nets = {\n",
    "    \"speaker_0\": ValueNet(obs_dim=speaker_obs_dim),\n",
    "    \"listener_0\": ValueNet(obs_dim=listener_obs_dim)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training MAGAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Disc Loss: 1.378, Policy Loss: -1.545\n",
      "Epoch 10 Disc Loss: 1.390, Policy Loss: -1.415\n",
      "Epoch 20 Disc Loss: 1.348, Policy Loss: -1.242\n",
      "Epoch 30 Disc Loss: 1.275, Policy Loss: -1.722\n",
      "Epoch 40 Disc Loss: 1.274, Policy Loss: -1.438\n",
      "Epoch 50 Disc Loss: 1.338, Policy Loss: -1.145\n",
      "Epoch 60 Disc Loss: 1.331, Policy Loss: -1.394\n",
      "Epoch 70 Disc Loss: 1.303, Policy Loss: -1.504\n",
      "Epoch 80 Disc Loss: 1.423, Policy Loss: -1.147\n",
      "Epoch 90 Disc Loss: 1.299, Policy Loss: -1.337\n",
      "Epoch 100 Disc Loss: 1.305, Policy Loss: -1.022\n",
      "Epoch 110 Disc Loss: 1.371, Policy Loss: -1.337\n",
      "Epoch 120 Disc Loss: 1.122, Policy Loss: -1.500\n",
      "Epoch 130 Disc Loss: 1.093, Policy Loss: -1.580\n",
      "Epoch 140 Disc Loss: 1.261, Policy Loss: -1.269\n",
      "Epoch 150 Disc Loss: 1.335, Policy Loss: -1.478\n",
      "Epoch 160 Disc Loss: 1.333, Policy Loss: -0.860\n",
      "Epoch 170 Disc Loss: 1.130, Policy Loss: -1.810\n",
      "Epoch 180 Disc Loss: 1.227, Policy Loss: -0.727\n",
      "Epoch 190 Disc Loss: 1.290, Policy Loss: -1.368\n",
      "Epoch 200 Disc Loss: 1.224, Policy Loss: -1.010\n",
      "Epoch 210 Disc Loss: 1.565, Policy Loss: -0.925\n",
      "Epoch 220 Disc Loss: 1.052, Policy Loss: -1.676\n",
      "Epoch 230 Disc Loss: 0.896, Policy Loss: -2.760\n",
      "Epoch 240 Disc Loss: 1.348, Policy Loss: -0.674\n",
      "Epoch 250 Disc Loss: 0.884, Policy Loss: -2.550\n",
      "Epoch 260 Disc Loss: 1.145, Policy Loss: -0.929\n",
      "Epoch 270 Disc Loss: 1.111, Policy Loss: -1.281\n",
      "Epoch 280 Disc Loss: 0.820, Policy Loss: -2.357\n",
      "Epoch 290 Disc Loss: 1.107, Policy Loss: -1.152\n",
      "Epoch 300 Disc Loss: 1.473, Policy Loss: -0.716\n",
      "Epoch 310 Disc Loss: 0.926, Policy Loss: -2.379\n",
      "Epoch 320 Disc Loss: 1.429, Policy Loss: -0.875\n",
      "Epoch 330 Disc Loss: 0.941, Policy Loss: -0.833\n",
      "Epoch 340 Disc Loss: 0.959, Policy Loss: -0.826\n",
      "Epoch 350 Disc Loss: 1.459, Policy Loss: -0.763\n",
      "Epoch 360 Disc Loss: 1.316, Policy Loss: -0.990\n",
      "Epoch 370 Disc Loss: 0.796, Policy Loss: -1.674\n",
      "Epoch 380 Disc Loss: 1.635, Policy Loss: -0.783\n",
      "Epoch 390 Disc Loss: 1.127, Policy Loss: -0.845\n",
      "Epoch 400 Disc Loss: 0.616, Policy Loss: -3.875\n",
      "Epoch 410 Disc Loss: 0.692, Policy Loss: -3.253\n",
      "Epoch 420 Disc Loss: 1.059, Policy Loss: -0.818\n",
      "Epoch 430 Disc Loss: 1.109, Policy Loss: -1.328\n",
      "Epoch 440 Disc Loss: 1.529, Policy Loss: -0.729\n",
      "Epoch 450 Disc Loss: 0.636, Policy Loss: -3.780\n",
      "Epoch 460 Disc Loss: 1.114, Policy Loss: -0.931\n",
      "Epoch 470 Disc Loss: 0.763, Policy Loss: -0.629\n",
      "Epoch 480 Disc Loss: 1.253, Policy Loss: -0.685\n",
      "Epoch 490 Disc Loss: 1.099, Policy Loss: -0.895\n",
      "Epoch 500 Disc Loss: 1.600, Policy Loss: -0.541\n",
      "Epoch 510 Disc Loss: 1.002, Policy Loss: -1.135\n",
      "Epoch 520 Disc Loss: 1.080, Policy Loss: -1.253\n",
      "Epoch 530 Disc Loss: 1.031, Policy Loss: -0.972\n",
      "Epoch 540 Disc Loss: 1.325, Policy Loss: -0.751\n",
      "Epoch 550 Disc Loss: 0.477, Policy Loss: -8.490\n",
      "Epoch 560 Disc Loss: 1.959, Policy Loss: -0.158\n",
      "Epoch 570 Disc Loss: 0.949, Policy Loss: -1.357\n",
      "Epoch 580 Disc Loss: 1.107, Policy Loss: -0.777\n",
      "Epoch 590 Disc Loss: 1.421, Policy Loss: -0.615\n",
      "Epoch 600 Disc Loss: 1.131, Policy Loss: -0.551\n",
      "Epoch 610 Disc Loss: 1.235, Policy Loss: -0.712\n",
      "Epoch 620 Disc Loss: 0.881, Policy Loss: -1.207\n",
      "Epoch 630 Disc Loss: 1.081, Policy Loss: -1.073\n",
      "Epoch 640 Disc Loss: 0.582, Policy Loss: -5.613\n",
      "Epoch 650 Disc Loss: 2.076, Policy Loss: -0.384\n",
      "Epoch 660 Disc Loss: 1.252, Policy Loss: -0.504\n",
      "Epoch 670 Disc Loss: 1.530, Policy Loss: -0.140\n",
      "Epoch 680 Disc Loss: 0.798, Policy Loss: -1.140\n",
      "Epoch 690 Disc Loss: 1.992, Policy Loss: -0.314\n",
      "Epoch 700 Disc Loss: 1.445, Policy Loss: -0.779\n",
      "Epoch 710 Disc Loss: 1.600, Policy Loss: -0.646\n",
      "Epoch 720 Disc Loss: 1.597, Policy Loss: -0.641\n",
      "Epoch 730 Disc Loss: 1.069, Policy Loss: -0.872\n",
      "Epoch 740 Disc Loss: 0.947, Policy Loss: -1.080\n",
      "Epoch 750 Disc Loss: 1.155, Policy Loss: -0.160\n",
      "Epoch 760 Disc Loss: 1.018, Policy Loss: -0.890\n",
      "Epoch 770 Disc Loss: 1.123, Policy Loss: -0.164\n",
      "Epoch 780 Disc Loss: 1.621, Policy Loss: -0.427\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 111\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[38;5;66;03m# eval_stats = evaluate_policy(learned_policy, num_episodes=20)\u001b[39;00m\n\u001b[0;32m    108\u001b[0m             \u001b[38;5;66;03m# print(f\"Epoch {epoch}: Success Rate={eval_stats['success_rate']:.2f}, Avg Reward={eval_stats['avg_reward']:.2f}\")\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     env\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 111\u001b[0m \u001b[43mtrain_magail\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpert_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[57], line 22\u001b[0m, in \u001b[0;36mtrain_magail\u001b[1;34m(expert_data, num_epochs, batch_size)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m env\u001b[38;5;241m.\u001b[39magents:\n\u001b[0;32m     21\u001b[0m     obs_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(obs[agent])\n\u001b[1;32m---> 22\u001b[0m     action_probs \u001b[38;5;241m=\u001b[39m \u001b[43mpolicies\u001b[49m\u001b[43m[\u001b[49m\u001b[43magent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Simpling from action distribution - enables exploration during training\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     action \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmultinomial(action_probs, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\wangy\\anaconda3\\envs\\Multi-Agent-General\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wangy\\anaconda3\\envs\\Multi-Agent-General\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[50], line 16\u001b[0m, in \u001b[0;36mPolicy.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wangy\\anaconda3\\envs\\Multi-Agent-General\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wangy\\anaconda3\\envs\\Multi-Agent-General\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\wangy\\anaconda3\\envs\\Multi-Agent-General\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\wangy\\anaconda3\\envs\\Multi-Agent-General\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wangy\\anaconda3\\envs\\Multi-Agent-General\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\wangy\\anaconda3\\envs\\Multi-Agent-General\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_magail(expert_data, num_epochs=1000, batch_size=32):\n",
    "    # Optimizers\n",
    "    optimizers = {\n",
    "        agent: {\n",
    "            \"policy\": torch.optim.Adam(policies[agent].parameters(), lr=1e-3),\n",
    "            \"disc\": torch.optim.Adam(discriminators[agent].parameters(), lr=1e-3),\n",
    "            \"value\": torch.optim.Adam(value_nets[agent].parameters(), lr=1e-3)\n",
    "        } for agent in [\"speaker_0\", \"listener_0\"]\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # --- Collect policy trajectories ---\n",
    "        env = make_env()\n",
    "        policy_data = {agent: {\"states\": [], \"actions\": []} for agent in env.agents}\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            actions = {}\n",
    "            for agent in env.agents:\n",
    "                obs_tensor = torch.FloatTensor(obs[agent])\n",
    "                action_probs = policies[agent](obs_tensor)\n",
    "                # Simpling from action distribution - enables exploration during training\n",
    "                action = torch.multinomial(action_probs, 1).item()\n",
    "                actions[agent] = action\n",
    "                policy_data[agent][\"states\"].append(obs[agent])\n",
    "                policy_data[agent][\"actions\"].append(action)\n",
    "            \n",
    "            obs, _, done, _, _ = env.step(actions)\n",
    "        \n",
    "        # --- Update discriminators ---\n",
    "        for agent in [\"speaker_0\", \"listener_0\"]:\n",
    "            # Expert data\n",
    "            expert_states = torch.FloatTensor(expert_data[agent][\"states\"])\n",
    "            expert_actions = torch.LongTensor(expert_data[agent][\"actions\"])\n",
    "            \n",
    "            # Policy data\n",
    "            policy_states = torch.FloatTensor(policy_data[agent][\"states\"])\n",
    "            policy_actions = torch.LongTensor(policy_data[agent][\"actions\"])\n",
    "\n",
    "             # One-hot encode actions (different for speaker/listener)\n",
    "            if \"speaker\" in agent:\n",
    "                num_classes = 3  # Speaker has 3 actions\n",
    "            else:\n",
    "                num_classes = 5  # Listener has 5 actions\n",
    "            \n",
    "            expert_actions_onehot = torch.nn.functional.one_hot(expert_actions, num_classes=num_classes).float()\n",
    "            policy_actions_onehot = torch.nn.functional.one_hot(policy_actions, num_classes=num_classes).float()\n",
    "            \n",
    "            # Discriminator loss\n",
    "            # TODO # Discriminator loss: max[log(D(expert)) + log(1 - D(policy))] => min[-log(D(expert)) - log(1 - D(policy))], \n",
    "            # but the formula given by the paper is inversed\n",
    "            real_loss = -torch.log(discriminators[agent](expert_states, expert_actions_onehot)).mean()\n",
    "            fake_loss = -torch.log(1 - discriminators[agent](policy_states, policy_actions_onehot)).mean()\n",
    "            disc_loss = real_loss + fake_loss\n",
    "            \n",
    "            optimizers[agent][\"disc\"].zero_grad()\n",
    "            disc_loss.backward()\n",
    "            optimizers[agent][\"disc\"].step()\n",
    "        \n",
    "        # --- Update policies (centralized training) ---\n",
    "        for agent in [\"speaker_0\", \"listener_0\"]:\n",
    "            states = torch.FloatTensor(policy_data[agent][\"states\"])\n",
    "            actions = torch.LongTensor(policy_data[agent][\"actions\"])\n",
    "            # One-hot encode actions\n",
    "            if \"speaker\" in agent:\n",
    "                num_classes = 3\n",
    "            else:\n",
    "                num_classes = 5\n",
    "            actions_onehot = torch.nn.functional.one_hot(actions, num_classes=num_classes).float()\n",
    "            \n",
    "            # TODO Here we did not use a base line as described in the paper?\n",
    "\n",
    "            # Adversarial reward: log(D(s,a))\n",
    "            # It seems to be: D(s,a) How much u think it is from the expert, so we wanna maximize this reward\n",
    "            # In paper it can be -log(D(s,a)) which outputs the probability that (s,a) from the policy\n",
    "            with torch.no_grad():\n",
    "                rewards = torch.log(discriminators[agent](states, actions_onehot))\n",
    "\n",
    "                # Compute value baseline\n",
    "                values = value_nets[agent](states)\n",
    "                # Compute advantages (reward-to-go - baseline)\n",
    "                advantages = rewards - values.squeeze()\n",
    "\n",
    "            # Update value network (MSE Loss)\n",
    "            value_loss = (values.squeeze() - rewards).pow(2).mean()\n",
    "            # Clear the gradient\n",
    "            optimizers[agent][\"value\"].zero_grad()\n",
    "            value_loss.requires_grad = True\n",
    "            value_loss.backward()\n",
    "            optimizers[agent][\"value\"].step()\n",
    "\n",
    "            # Policy gradient\n",
    "            action_probs = policies[agent](states)\n",
    "            log_probs = torch.log(action_probs.gather(1, actions.unsqueeze(1)))\n",
    "\n",
    "            # If we didn't call advantage.detach(), the gradients would flow through the advantage tensor, and the value network's parameters would be updated using the policy loss, which is not what we want.\n",
    "            policy_loss = -(log_probs * advantages.detach()).mean()\n",
    "            \n",
    "            optimizers[agent][\"policy\"].zero_grad()\n",
    "            policy_loss.backward()\n",
    "            optimizers[agent][\"policy\"].step()\n",
    "        \n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch} Disc Loss: {disc_loss.item():.3f}, Policy Loss: {policy_loss.item():.3f}\")\n",
    "            # eval_stats = evaluate_policy(learned_policy, num_episodes=20)\n",
    "            # print(f\"Epoch {epoch}: Success Rate={eval_stats['success_rate']:.2f}, Avg Reward={eval_stats['avg_reward']:.2f}\")\n",
    "\n",
    "    env.close()\n",
    "train_magail(expert_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Learned Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate expert policy\n",
    "expert_stats = evaluate_policy(expert_policy, num_episodes=100, is_expert=True)\n",
    "\n",
    "# Evaluate learned policy\n",
    "learned_stats = evaluate_policy(learned_policy, num_episodes=100)\n",
    "\n",
    "# (Optional) Evaluate random policy\n",
    "def random_policy(obs, _):\n",
    "    return {agent: env.action_space(agent).sample() for agent in obs.keys()}\n",
    "random_stats = evaluate_policy(random_policy, num_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['Expert', 'Learned', 'Random']\n",
    "metrics = ['success_rate', 'avg_reward', 'avg_steps']\n",
    "titles = ['Success Rate', 'Average Reward', 'Average Steps']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "    expert_val = expert_stats[metric]\n",
    "    learned_val = learned_stats[metric]\n",
    "    random_val = random_stats[metric]\n",
    "    \n",
    "    axes[idx].bar(labels, [expert_val, learned_val, random_val], color=['green', 'blue', 'red'])\n",
    "    axes[idx].set_title(title)\n",
    "    axes[idx].set_ylabel(title)\n",
    "    \n",
    "    if metric == 'success_rate':\n",
    "        axes[idx].set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multi-Agent-General",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
