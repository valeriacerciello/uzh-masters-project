{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Single-Agent Q-learning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "import gym\n",
    "from gym import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorldEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Custom 2D Grid World environment in Gym.\n",
    "    Gym is for building and testing RL environments.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, grid_size=(3, 3), start=(0, 0), goal=(2, 2), gamma = 0.9):\n",
    "        super(GridWorldEnv, self).__init__()\n",
    "\n",
    "        # Define the grid world size\n",
    "        self.grid_size = grid_size\n",
    "\n",
    "        # Define start and goal positions\n",
    "        self.start = start\n",
    "        self.goal = goal\n",
    "\n",
    "        # Set the current position to the start\n",
    "        self.agent_pos = np.array(self.start)\n",
    "\n",
    "        # Define action space: 4 possible actions (up, down, left, right)\n",
    "        # spaces.Discrete is used to create a space of a finite set of elements\n",
    "        self.action_space = spaces.Discrete(4)  # 0 = down, 1 = left, 2 = up, 3 = right\n",
    "\n",
    "        # Define observation space (agent's position in the grid)\n",
    "        # cartesian product of n closed intervals\n",
    "        self.observation_space = spaces.Box(low=0, high=max(grid_size), shape=(2,), dtype=np.int32)\n",
    "\n",
    "        # State-value function initialized to 0\n",
    "        self.V = np.zeros(self.grid_size)\n",
    "\n",
    "        # Initialize the policy (a random policy for now, can be updated later)\n",
    "        # Policy: a 5x5 grid where each entry is one of the actions (0=down, 1=left, 2=up, 3=right)\n",
    "        self.policy = np.random.choice([0, 1, 2, 3], size=self.grid_size)\n",
    "\n",
    "        # Define discount rate\n",
    "        self.gamma = gamma\n",
    "\n",
    "        # Define the movement directions corresponding to actions\n",
    "        self.movement = {\n",
    "            0: np.array([1, 0]),  # down\n",
    "            1: np.array([0, -1]),  # left\n",
    "            2: np.array([-1, 0]),  # up\n",
    "            3: np.array([0, 1])  # right\n",
    "        }\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reset the environment to the initial state (start position).\n",
    "        \"\"\"\n",
    "        self.agent_pos = np.array(self.start)\n",
    "        return self.agent_pos\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Perform an action and update the environment's state.\n",
    "        \"\"\"\n",
    "        # Update the agent's position\n",
    "        next_pos = self.agent_pos + self.movement[action]\n",
    "\n",
    "        # Check if the new position is within grid bounds\n",
    "        if self._is_valid(next_pos):\n",
    "            self.agent_pos = next_pos\n",
    "\n",
    "        # Check if the agent has reached the goal\n",
    "        if tuple(self.agent_pos) == self.goal:\n",
    "            reward = 10  # Large reward for reaching the goal\n",
    "            done = True\n",
    "        else:\n",
    "            reward = -1  # Small step penalty\n",
    "            done = False\n",
    "\n",
    "        return self.agent_pos, reward, done, {}\n",
    "\n",
    "    def _is_valid(self, pos):\n",
    "        \"\"\"\n",
    "        Check if the new position is valid (within bounds).\n",
    "        \"\"\"\n",
    "        # Check if position is within bounds\n",
    "        if 0 <= pos[0] < self.grid_size[0] and 0 <= pos[1] < self.grid_size[1]:\n",
    "            return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 completed.\n",
      "Episode 100 completed.\n",
      "Episode 200 completed.\n",
      "Episode 300 completed.\n",
      "Episode 400 completed.\n",
      "Episode 500 completed.\n",
      "Episode 600 completed.\n",
      "Episode 700 completed.\n",
      "Episode 800 completed.\n",
      "Episode 900 completed.\n",
      "Training complete! Learned Q-table:\n",
      "[[[ 3.78994577  2.75282469  2.85694283  4.58      ]\n",
      "  [ 6.2         2.98436899  3.65829767  5.43484101]\n",
      "  [ 7.94346384  0.7812539   0.32672639  0.7381616 ]]\n",
      "\n",
      " [[-0.42661     0.07884832 -0.6007095   6.17183384]\n",
      "  [ 6.84758704  3.97622471  4.21253539  8.        ]\n",
      "  [10.          5.75048138  4.8119574   7.20582059]]\n",
      "\n",
      " [[-0.199      -0.199      -0.19        0.72475026]\n",
      "  [-0.1        -0.199      -0.1         9.74968445]\n",
      "  [ 0.          0.          0.          0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "def q_learning(env, episodes=1000, alpha=0.1, gamma=0.9, epsilon=0.1):\n",
    "    # initializing Q table with zeros \n",
    "    Q = np.zeros((*env.grid_size, env.action_space.n)) # every cell contains the Q value for choosing a certain action\n",
    "\n",
    "    # start of episode (place the agent at the start and set done to false)\n",
    "    for episode in range(episodes):\n",
    "        state = tuple(env.reset())  # Reset environment\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            # Choose action using epsilon-greedy policy\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = env.action_space.sample()  # Explore\n",
    "            else:\n",
    "                action = np.argmax(Q[state])  # Exploit best known action\n",
    "\n",
    "            # Take action and observe next state & reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            next_state = tuple(next_state)\n",
    "\n",
    "            # Q-value update using Bellman equation\n",
    "            Q[state + (action,)] += alpha * (reward + gamma * np.max(Q[next_state]) - Q[state + (action,)])\n",
    "\n",
    "            # Move to the next state\n",
    "            state = next_state\n",
    "\n",
    "        # Optional: Print progress\n",
    "        if episode % 100 == 0:\n",
    "            print(f\"Episode {episode} completed.\")\n",
    "\n",
    "    return Q\n",
    "\n",
    "\n",
    "# Train the agent\n",
    "env = GridWorldEnv()\n",
    "Q_table = q_learning(env)\n",
    "print(\"Training complete! Learned Q-table:\")\n",
    "print(Q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Policy:\n",
      "[[3 0 0]\n",
      " [3 3 0]\n",
      " [3 3 0]]\n"
     ]
    }
   ],
   "source": [
    "def extract_policy(Q):\n",
    "    \"\"\"\n",
    "    Extracts the optimal policy from the Q-table.\n",
    "    \"\"\"\n",
    "    policy = np.argmax(Q, axis=-1)  # Best action for each state\n",
    "    return policy\n",
    "\n",
    "optimal_policy = extract_policy(Q_table)\n",
    "print(\"Optimal Policy:\")\n",
    "print(optimal_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid_with_policy(env):\n",
    "    \"\"\"This method plots the environment of the agent and shows the policy arrows.\n",
    "    Works for grid environments.\n",
    "\n",
    "    Args:\n",
    "        env (GridWorldEnv): The environment to be plotted.\n",
    "    \"\"\"\n",
    "    # Create a copy of the environment grid\n",
    "    grid = np.zeros(env.grid_size)\n",
    "\n",
    "    # Define custom colors for the colormap\n",
    "    colors = ['white', 'black']  # 'white' for free cells\n",
    "    cmap = mcolors.ListedColormap(colors)\n",
    "\n",
    "    # Plot the grid with the custom colormap\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.matshow(grid, cmap=cmap)\n",
    "\n",
    "    # Display 'F' for the finish line\n",
    "    ax.text(env.goal[1], env.goal[0], 'F', ha='center', va='center', color='black', fontsize=20)\n",
    "    ax.text(env.start[1], env.start[0], 'S', ha='center', va='center', color='black', fontsize=20)\n",
    "\n",
    "    # Define arrow directions based on policy actions\n",
    "    action_arrows = {\n",
    "        0: '↓',  # down\n",
    "        1: '←',  # left\n",
    "        2: '↑',  # up\n",
    "        3: '→'   # right\n",
    "    }\n",
    "\n",
    "    # Place arrows on the grid based on the policy\n",
    "    for i in range(env.grid_size[0]):\n",
    "        for j in range(env.grid_size[1]):\n",
    "            if (i, j) == env.goal:\n",
    "                continue\n",
    "            action = optimal_policy[i, j]  # Get action for the current state\n",
    "            ax.text(j, i, action_arrows[action], ha='center', va='center', color='blue', fontsize=20)\n",
    "\n",
    "    # Add grid lines separating each square\n",
    "    ax.set_xticks(np.arange(-0.5, env.grid_size[1], 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-0.5, env.grid_size[0], 1), minor=True)\n",
    "    ax.grid(which='minor', color='black', linestyle='-', linewidth=1)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    plt.title(\"Grid World with Optimal Policy Arrows\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_value_function(env):\n",
    "    \"\"\"Plot the value function with respect to an end point, including grid lines.\"\"\"\n",
    "    grid = env.V.copy()\n",
    "\n",
    "    # Create a new figure\n",
    "    plt.figure()\n",
    "\n",
    "    # Plot the grid representing the value function\n",
    "    plt.imshow(grid, cmap='Purples', interpolation='nearest', aspect='auto')\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Agent's value function\")\n",
    "\n",
    "    # Add grid lines to the plot\n",
    "    ax = plt.gca()  # Get the current axis\n",
    "    ax.set_xticks(np.arange(-0.5, env.grid_size[1], 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-0.5, env.grid_size[0], 1), minor=True)\n",
    "    ax.grid(which='minor', color='black', linestyle='-', linewidth=2)  # Add the grid lines\n",
    "\n",
    "    # Hide the tick labels (optional, for a cleaner plot)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAGeCAYAAACOzJagAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAnO0lEQVR4nO3deXhU9b3H8c9MQogBksgS2SxBISyCIghIIKwKBIQgwTZVlgiVFsIiPBUXtAX1+lQsikjYFPHK0qItilUWCaAmgAJhuxYMgsBFVCCRpWwJJL/7R+6MDPllJckE5v16nnmYOed3znzP/HLO52wzOIwxRgAAXMXp7QIAABUTAQEAsCIgAABWBAQAwIqAAABYERAAACsCAgBgRUAAAKwICACAlU8GRHx8vMLDwwttd+jQITkcDr3zzjtlXtO16tq1q7p27Vpou88++0wOh0OfffaZV+twtW3RokWZ1FGWwsPDFR8f7zPv/c4778jhcOjQoUPuYcXpZ1y/rquAOHjwoMaMGaOIiAgFBQUpKChIzZs3V0JCgnbv3u2VmrZs2SKHw6HXXnstz7iYmBg5HA4tXLgwz7jOnTurXr165VGiV/3www+aMmWKdu7cWSbzv3TpkmbOnKm2bduqWrVqqlq1qtq2bauZM2fq0qVLJZ7vpk2bNGXKFJ06dar0ii1HDofD/XA6napbt6569uxZZjsG5Sk7O1t169aVw+HQqlWrvF3ODc3f2wUU1ccff6zf/OY38vf31yOPPKK77rpLTqdT33zzjZYvX645c+bo4MGDatCgQaHzevPNN5WTk1MqdbVu3VpBQUFKSUnRhAkTPMZt2rRJ/v7+2rhxox599FH38KysLG3dulX9+vUrlRoqkk8//dTj9Q8//KCpU6cqPDxcrVq1KtX3OnfunPr27avPP/9cDzzwgOLj4+V0OrV69WqNHz9ey5cv1yeffKIqVaoUe96bNm3S1KlTFR8fr9DQUI9xaWlpcjor/r7V/fffr6FDh8oYo4MHD2r27Nnq3r27PvnkE0VHR1/TvK/u5/K0fv16/fjjjwoPD9eSJUuueVmQv+siIA4cOKC4uDg1aNBA69atU506dTzGv/zyy5o9e3ahK+25c+dUpUoVVapUqdRq8/f3V/v27bVx40aP4WlpaUpPT9fDDz+slJQUj3Gpqam6ePGiOnXqdM3vf/78eQUFBV3zfEpLQEBAub3XxIkT9fnnn+uNN97QmDFj3MNHjRqlxMREjRkzRn/84x81Z86cUn3fypUrl+r8ykpERIQGDx7sfv3ggw/qzjvv1IwZM655o1qe/Xy1xYsXq3Xr1ho2bJieeeYZ93pdmPza5eTkKCsrS4GBgWVR7nWt4u8GSZo2bZrOnTunhQsX5gkHKXcjPW7cON16663uYfHx8apataoOHDigPn36qFq1anrkkUfc466+BnHq1CnFx8crJCREoaGhGjZsWJFPL3Tq1EnHjh3T/v373cM2btyo4OBgjRw50h0WV45zTecye/Zs3XHHHapcubLq1q2rhISEPO/vOmefmpqqzp07KygoSM8880y+dX3//fcaMGCAqlSporCwME2YMEGZmZmFLs/u3bvlcDj00UcfuYelpqbK4XCodevWHm2jo6PVvn17jxpd56Y/++wztW3bVpL06KOPuk95XH1NZ8+ePerWrZuCgoJUr149TZs2rdAav//+ey1YsEDdu3f3CAeXhIQEdevWTW+99Za+//5793CHw6ExY8ZoyZIlatKkiQIDA9WmTRt98cUX7jZTpkzRE088IUlq2LChu27XOfirrwO4ztGnpKRo3LhxqlWrlkJDQ/X73/9eWVlZOnXqlIYOHaqbb75ZN998syZNmqSrf0T5r3/9qyIjI1WjRg3ddNNNatOmjf7xj38U+jkUR8uWLVWzZk0dPHjQPWz9+vWKiopSlSpVFBoaqpiYGO3du7fQedmuQVy8eFFTpkxRRESEAgMDVadOHQ0cOFAHDhyQMUbh4eGKiYnJM6+LFy8qJCREv//97wt93wsXLuiDDz5QXFycfv3rX+vChQtasWJFnnYFrf9X/g241rnVq1dLknbs2KHo6GgFBweratWq6tGjh7788kv3fE+dOiU/Pz/NnDnTPSw9PV1Op1M1atTw6NdRo0apdu3a7tfffvutYmNjVbt2bQUGBqp+/fqKi4vT6dOnC11ub7kuAuLjjz9Wo0aNPDZERXH58mX16tVLYWFh+utf/6rY2FhrO2OMYmJitGjRIg0ePFgvvviivv/+ew0bNqxI7+Pa0F95pLBx40bde++9at++vSpVqqRNmzZ5jKtWrZruuusuSbkbpISEBNWtW1fTp09XbGys5s2bp549e+Y5j56RkaHo6Gi1atVKM2bMULdu3aw1XbhwQT169NCaNWs0ZswYTZ48WcnJyZo0aVKhy9OiRQuFhoZ6bDSTk5PldDq1a9cunTlzRlLuntemTZvUuXNn63yaNWum559/XpI0cuRILVq0SIsWLfJof/LkSfXu3Vt33XWXpk+frqZNm+rJJ58s9NzyqlWrlJ2draFDh+bbZujQobp8+bJ75Xf5/PPP9fjjj2vw4MF6/vnnlZGRod69e+vrr7+WJA0cOFC//e1vJUmvvfaau+5atWoVWNPYsWP17bffaurUqerfv7/mz5+v5557Tv369VN2drZeeuklderUSa+88ooWLVrkMe3rr7+uu+++W88//7xeeukl+fv766GHHtInn3xS4HsWx8mTJ3Xy5EnVqFFDkpSUlKRevXrp+PHjmjJliiZOnKhNmzapY8eOHhekiyI7O1sPPPCApk6dqjZt2mj69OkaP368Tp8+ra+//loOh0ODBw/WqlWr9PPPP3tM+69//UtnzpzxONrJz0cffaSzZ88qLi5OtWvXVteuXbVkyRJr24LW//Xr12vChAn6zW9+o9dff13h4eH697//raioKO3atUuTJk3Sc889p4MHD6pr16766quvJEmhoaFq0aKFx7qRkpIih8Ohn3/+WXv27HEPT05OVlRUlKTc08q9evXSl19+qbFjxyoxMVEjR47Ud999V7Gvc5kK7vTp00aSGTBgQJ5xJ0+eNCdOnHA/zp8/7x43bNgwI8k89dRTeaYbNmyYadCggfv1hx9+aCSZadOmuYddvnzZREVFGUlm4cKFBdZ45swZ4+fnZ0aMGOEe1qRJEzN16lRjjDHt2rUzTzzxhHtcrVq1zP3332+MMeb48eMmICDA9OzZ02RnZ7vbzJo1y0gyb7/9tntYly5djCQzd+7cPDV06dLFdOnSxf16xowZRpJ577333MPOnTtnGjVqZCSZDRs2FLhMffv2Ne3atXO/HjhwoBk4cKDx8/Mzq1atMsYYs337diPJrFixIt86tm7dmu9n6Fqed9991z0sMzPT1K5d28TGxhZY3+OPP24kmR07duTbxlXfxIkT3cMkGUlm27Zt7mGHDx82gYGB5sEHH3QPe+WVV4wkc/DgwTzzbdCggRk2bJj79cKFC40k06tXL5OTk+Me3qFDB+NwOMwf/vAH97DLly+b+vXre3xGxhiPv11jjMnKyjItWrQw3bt3L/C98yPJjBgxwpw4ccIcP37cfPXVV6ZHjx5Gkpk+fboxxphWrVqZsLAwk5GR4Z5u165dxul0mqFDh+ZZvis/i6v7+e233zaSzKuvvpqnFtdnkpaWZiSZOXPmeIzv37+/CQ8P9/js8vPAAw+Yjh07ul/Pnz/f+Pv7m+PHj3u0K2j9l2ScTqf597//7TF8wIABJiAgwBw4cMA97IcffjDVqlUznTt3dg9LSEgwt9xyi/v1xIkTTefOnU1YWJh72TIyMozD4TCvv/66McaYHTt2GEnm/fffL3QZK5IKfwTh2lutWrVqnnFdu3ZVrVq13I/ExMQ8bUaNGlXoe6xcuVL+/v4ebf38/DR27Ngi1VitWjXdeeed7iOI9PR0paWlKTIyUpLUsWNH92mlffv26cSJE+6jjqSkJGVlZenxxx/3uIby2GOPKTg4OM8eZOXKlT0ueBe0THXq1NGgQYPcw4KCgjRy5MgiLVNUVJS2b9+uc+fOScrdS+rTp49atWql5ORkSbl7SA6H45qupVStWtVjzzEgIEDt2rXTd999V+B0//nPfyTlfvb5cY1z/Q25dOjQQW3atHG//tWvfqWYmBitWbNG2dnZxV4GlxEjRsjhcLhft2/fXsYYjRgxwj3Mz89P99xzT57lu+mmm9zPT548qdOnT7v7oKQWLFigWrVqKSwszH2dbOLEiXr88cf1448/aufOnYqPj1f16tXd09x55526//77tXLlymK91z//+U/VrFnTus64PpOIiAi1b9/eY4//559/1qpVq/TII494fHY2GRkZWrNmjfvoTpJiY2PlcDj03nvvWafJb/3v0qWLmjdv7n6dnZ2tTz/9VAMGDNBtt93mHl6nTh33dUTX31FUVJSOHTumtLQ0SbnrQefOnRUVFeVeN1JSUmSMcR9BhISESJLWrFmj8+fPF7icFUmFDwjXSn727Nk84+bNm6e1a9dq8eLF1mn9/f1Vv379Qt/j8OHDqlOnTp4QatKkSZHr7NSpk/taw6ZNm+Tn56d7771XkhQZGanU1FRlZmbmuf5w+PBh63sFBATotttuc493qVevXpEuEB4+fFiNGjXKs9IVdZmioqJ0+fJlbd68WWlpaTp+/LiioqLUuXNnj4Bo3ry5xwamuOrXr5+nxptvvlknT54scDrX34UrKGzyC5HGjRvnaRsREaHz58/rxIkTRarb5le/+pXHa9dG4cprY67hVy/fxx9/rHvvvVeBgYGqXr26atWqpTlz5lzT+emYmBitXbtWSUlJ+uqrr5Senq7p06fL6XTm+3cn5Z4aTE9Pd+8cFMWBAwfUpEkT+fsXfN/L0KFDtXHjRvf7v//++7p06ZKGDBlS6HssW7ZMly5d0t133639+/dr//79+vnnn/OEjktB63/Dhg09Xp84cULnz5/P9/PIycnRkSNHJMm90U9OTta5c+e0Y8cO67oRHBzsPo3csGFDTZw4UW+99ZZq1qypXr16KTExsUJff5Cug4AICQlRnTp13OeHr9S+fXvdd9996tixo3XaypUrl9vtiK4N/saNG7Vx40a1bNnSHTiRkZHKzMzU1q1blZKSIn9/f3d4FNeVe5pl6Z577lFgYKC++OILJScnKywsTBEREYqKitKWLVuUmZnpcY61pPz8/KzDTSH/E26zZs0kqcDvv7jGXbmnWJbyWxbb8CuXLzk5Wf3791dgYKBmz56tlStXau3atXr44YcL/RwKUr9+fd13333q0aOH2rVrV6LbfUtbXFycKlWq5N6gL168WPfcc0+Rdlxc03Ts2FGNGzd2P1JSUrR58+Y8R2UFrf/Xsh7VrVtXDRs21BdffKHNmzfLGKMOHTooKipKR44c0eHDh5WcnKzIyEiP958+fbp2796tZ555RhcuXNC4ceN0xx13eNxEUdFU+ICQpL59+2r//v3asmVLmcy/QYMG+vHHH/McpbgOIYviygvVGzdu9AitunXrqkGDBu7wuPvuu923prq+t3H1e2VlZRX5ex35LZPr7pGSLJPrVE9ycrJHEERFRSkzM1NLlizRsWPH8r1A7VLYaYOSio6Olp+fX56LvVd699135e/vr969e3sM//bbb/O03bdvn4KCgtwXosuqbpt//vOfCgwM1Jo1azR8+HBFR0frvvvuK9P3zO/vTpK++eYb1axZs1iBcvvttystLa3QLydWr15dffv21ZIlS3T48GFt3LixSEcPBw8e1KZNmzRmzBi9//77Ho9ly5YpICBAS5cuLXK9V6tVq5aCgoLy/TycTqfHkaDrdFJycrJatWrlvukkJCREq1ev1vbt263rRsuWLfXss8+6d7yOHj2quXPnlrjusnZdBMSkSZMUFBSk4cOH69ixY3nGX8teliT16dNHly9f9rhfPjs7W2+88UaR5+Haq1i3bp22bdvmvv7gEhkZqQ8//FBpaWke5+zvu+8+BQQEaObMmR7LsWDBAp0+fVp9+/Yt8TL98MMPHrdKnj9/XvPnzy/yPKKiovTVV19pw4YN7oCoWbOmmjVrppdfftndpiCujUxp36lx66236tFHH1VSUpL1ew5z587V+vXrNWLEiDynGTZv3uxxbv/IkSNasWKFevbs6d7bL6u6bfz8/ORwODyufxw6dEgffvhhmb1nnTp11KpVK/33f/+3xzJ+/fXX+vTTT9WnT59izS82Nlbp6emaNWtWnnFXr59DhgzRnj179MQTT8jPz09xcXGFzt919DBp0iQNGjTI4/HrX/9aXbp0yfdupqLw8/NTz549tWLFCo87uI4dO6alS5eqU6dOCg4Odg+PiorSoUOHtGzZMvc64HQ6FRkZqVdffVWXLl3yWDfOnDmjy5cve7xny5Yt5XQ6i3TrubdcF1+Ua9y4sZYuXarf/va3atKkifub1Ob/vyG6dOlSOZ3OIl1vsOnXr586duyop556SocOHVLz5s21fPnyYp8f7NSpk3uP9urTXpGRkfrb3/7mbudSq1YtPf3005o6dap69+6t/v37Ky0tTbNnz1bbtm2LdOufzWOPPaZZs2Zp6NChSk1NVZ06dbRo0aJifakuKipK//Vf/6UjR454/LF37txZ8+bNU3h4eKGf+e23367Q0FDNnTtX1apVU5UqVdS+ffs854BL4rXXXtM333yj0aNHa/Xq1e4jhTVr1mjFihXq0qWLpk+fnme6Fi1aqFevXho3bpwqV66s2bNnS5KmTp3qbuO6iD158mT3aZF+/fqVyWmavn376tVXX1Xv3r318MMP6/jx40pMTFSjRo3K9CdkXnnlFUVHR6tDhw4aMWKELly4oDfeeEMhISGaMmVKseY1dOhQvfvuu5o4caK2bNmiqKgonTt3TklJSRo9erTH9x/69u2rGjVq6P3331d0dLTCwsIKnf+SJUvUqlWrPNdzXPr376+xY8dq+/bteb6rU1Qvvvii1q5dq06dOmn06NHy9/fXvHnzlJmZmee7Oa71IS0tTS+99JJ7eOfOnbVq1SpVrlzZ/R0gKfe22jFjxuihhx5SRESELl++rEWLFsnPzy/f2+8rBC/dPVUi+/fvN6NGjTKNGjUygYGB5qabbjJNmzY1f/jDH8zOnTs92g4bNsxUqVLFOp+rb3M1Jve2tCFDhpjg4GATEhJihgwZ4r41rbDbXF3mzZtnJJl69erlGee65VKSOXbsWJ7xs2bNMk2bNjWVKlUyt9xyixk1apQ5efKkR5suXbqYO+64w/reV992aEzu7Zv9+/c3QUFBpmbNmmb8+PFm9erVRbrN1Zhfbt+tVq2auXz5snv44sWLjSQzZMiQItWxYsUK07x5c+Pv7+/xeea3PLb+yU9mZqZ57bXXTJs2bUyVKlVMUFCQad26tZkxY4bJysrK016SSUhIMIsXLzaNGzc2lStXNnfffbf183jhhRdMvXr1jNPp9LjNM7/bXLdu3eox/Z///GcjyZw4cSLP8l39t7lgwQJ3PU2bNjULFy50T3+l4tzmmpCQUGi7pKQk07FjR3PTTTeZ4OBg069fP7Nnzx6PNkW5zdWY3Ft1J0+ebBo2bGgqVapkateubQYNGuRx26jL6NGjjSSzdOnSQmtMTU01ksxzzz2Xb5tDhw4ZSWbChAnGmILX/4I+m+3bt5tevXqZqlWrmqCgINOtWzezadMma9uwsLA863NKSoqRZKKiojzafvfdd2b48OHm9ttvN4GBgaZ69eqmW7duJikpqcBl9zaHMdd4fga4jjgcDiUkJFhPhaD8TJgwQQsWLNBPP/1UoX4qBp6ui2sQAG4cFy9e1OLFixUbG0s4VHDXxTUIANe/48ePKykpSf/4xz+UkZGh8ePHe7skFIKAAFAu9uzZo0ceeURhYWGaOXNmqf/8O0of1yAAAFYlugZh+80j3Jjoa99BX/uOovZ1iY4gmjdv7vGztrhx0de+g772HUXt62Jfg3D970unT58u158jgHdkZ2fn+TVU3Jjoa99gjFFWVpZycnIK/a26Ih9BJCYmKjExUVlZWTpw4ECpFAoA8I4jR44U+ksIxT7FdPr0aYWGhur111/nLoQbXFpamkaOHKn58+cX66fPcf2hr33Hzp07NX78eJ06dcr9k/T5KfYpJtdppVatWhX6S564vrl+rrxNmzYl/n0bXB/oa99TlEsEfJMaAGBFQAAArAgIAIAVAQEAsCIgAABWBAQAwIqAAABYERAAACsCAgBgRUAAAKwICACAFQEBALAiIAAAVgQEAMCKgAAAWBEQAAArAgIAYEVAAACsCAgAgBUBAQCwIiAAAFYEBADAioAAAFgREAAAKwICAGBFQAAArAgIAIAVAQEAsCIgAABWBAQAwIqAAABYERAAACsCAgBgRUAAAKwICACAFQEBALAiIAAAVgQEAMCKgAAAWBEQAAArAgIAYEVAAACsCAgAgBUBAQCwIiAAAFYEBADAyt/bBVRU586d06JFi/TRRx9p165dysjIkDFGwcHBCg8PV8uWLdWhQwf17t1bt956q7fLRSlKSpJSUqT69aXf/c7b1aAs0dcFIyAsNm/erLi4OP3v//5vnnHp6elKT0/Xtm3btHDhQt1yyy366aefvFAlykpSkvTyy1L79mw0bnT0dcEIiKvs27dPvXr10n/+8x9JUv/+/TVo0CBFREQoICBA6enp2rVrl9auXasNGzZ4uVoAKDsExFUmT57sDoeFCxcqPj4+T5v7779ff/zjH3XixAm999575VwhAJQPLlJfITs7W5988okk6Z577rGGw5Vq1aqlhISEcqgMAMofAXGFEydO6MKFC5KkRo0aebkaAPAuAuIKAQEB7ud79+4tsG1mpjR+vJSeXtZVAYB3EBBXqF69uho0aCBJ2rVrl15++WXl5ORY2w4aJM2cKfXoQUgAuDEREFcZO3as+/lTTz2l22+/XePHj9eyZct08OBB97jYWMnplHbvzg2JjAxvVAsAZYeAuMqECRM0fPhw9+tDhw5p5syZiouL02233abatWsrLi5ONWr8S/PnGzkcuSHRvTshAeDGQkBcxel0asGCBfr000/Vu3dv+ft73gl87NgxLVu2TP3799fcue304ovH3SHBkQSAG4nPfw9i7lxp1CjbmPv//5G/bdtyHy67dkkxMblf3QeA6x1HEKXs1ClvVwAApcPnjyDi4qSuXYs/XUpKih577HeS7pM0U5JTdetKy5eXbn0A4C0+HxChobmP4mratJOeeeZunTgxTZJTtWtna8MGP0VElHKBKHPr1kl/+Yv0wQdS1ap5xxsjjR4tRURIEyaUf30oPfR18fh8QJTU+vVSRsZCSYGSjurDD29SRER1b5eFYjp6VOrfXzp/XoqOllavzttm3Ljca1WS1LRpbjtcf+jr4uMaRAk9+2y2cnJyw6FKlX5q1+5mb5eEEqhXT3rhhdznKSlSnz7SuXO/jJ8wQZo1K/d5XJzUs2f514jSQV8XHwFxhbNnz6p9+/b6+OOP8/0GtSTl5OTottsmSFopqZsefPAOORyOcqsTpWviRGnatNznX3whzZmT+3zbNmnGjNznDz0kLVok+fl5pUSUEvq6eDjFdJUtW7aoX79+qlevngYMGKAOHTqoQYMGqlatmk6dOqUdO3bo7bff1v/8z/9IekMhISF6wbVbguvWE09IOTnSU09J2dm5w1z/DhwoLV0q+bO23BDo66LjY7iCv7+/ateurZ9++klHjx5VYmKiEhMT823fuHFj/e1vf1N4eHj5FYky8+STuRuOZ575ZVhMjPT3v7PBuNHQ10XDR3GFwMBAHT16VF9++aWSkpL05ZdfKi0tTceOHdPFixdVpUoV1a1bV3fddZdiYmIUGxvr8QuwuP49/XTuhuPZZ6UHHpDee0+qVMnbVaEs0NeFIyCu4nQ6FRkZqcjISG+XAi+ZPDn3gRsffV0wLlIDAKwICACAFQEBALAiIAAAVgQEAMCKgAAAWBEQAAArAgIAYEVAAACsCAgAgBUBAQCwIiAAAFYEBADAioAAAFgREAAAKwICAGBFQAAArAgIAIAVAQEAsCIgAABWBAQAwIqAAABYERAAACsCAgBgRUAAAKwICACAFQEBALAiIAAAVgQEAMCKgAAAWBEQAAArAgIAYEVAAACsCAgAgBUBAQCwIiAAAFYEBADAioAAAFgREAAAKwICAGBFQAAArAgIAIAVAQEAsCIgAABWBAQAwIqAAABYERAAACsCAgBgRUAAAKwICACAFQEBALDyL+mEaWlpqlq1amnWggpm7969Hv/ixkVf+460tLQit3UYY0xRGiYmJioxMVHZ2dnat29fiYsDAHjf6dOnFRwcXGCbIgeEy5kzZxQSEqL58+erTZs211QgKra9e/dq8ODBWrx4sZo1a+btclCG6GvfkZqaqpEjRxYpIEp8iqlJkyZq3bp1SSfHdaRZs2b0tY+gr298Z8+eLXJbLlIDAKwICACAFQEBALAiIAAAVgQEAMCKgAAAWBEQAAArAgIAYEVAAACsCAgAgBUBAQCwIiAAAFYEBADAioAAAFgREAAAKwICAGBFQAAArAgIAIAVAQEAsCIgAABWBAQAwIqAAABYERAAACsCAgBgRUAAAKwICACAFQEBALAiIAAAVgQEAMCKgAAAWBEQAAArAgIAYEVAAACsCAgAgBUBAQCwIiAAAFYEBADAioAAAFgREAAAKwICAGBFQAAArAgIAIAVAQEAsCIgAABWBAQAwIqAAABY+Xu7AADwlqQkKSVFql9f+t3vvF1NxcMRBACflZQkTZ0qvfWWtyupmAgIAIAVAQEAsCIgAABWBAQAwIqAKKHMTGn8eCk93duVoDzQ3/BFBEQJDRokzZwp9ejBRsMX0N/wRQRECcXGSk6ntHt37kYjI8PbFaEs0d/wRQRECcXHS2++KTkcuRuN7t3ZaNzI6G/4IgLiGgwfLs2f/8tGgz3LGxv9DV/j8wExd27uCl/Sx2OPScbkzmvXLikmxrvLg4LR30DR+XxAlLZTp7xdAcoT/Y0bmc//WF9cnNS1a8mnT0qSxo3L3ausW1davrzUSkMZoL+BovP5gAgNzX2UxLp10qRJv2wsNmyQIiJKszqUNvrbt61bJ/3lL9IHH0hVq+Ydb4w0enRuv06YUP71VTQ+HxAltX691K+fdOECGwtfQH9f/44elfr3l86fl6KjpdWr87YZNy73OpUkNW2a286XcQ2ihP70JzYWvoT+vv7Vqye98ELu85QUqU8f6dy5X8ZPmCDNmpX7PC5O6tmz/GusaAiIEvroo9y9CzYWvoH+vjFMnChNm5b7/IsvpDlzcp9v2ybNmJH7/KGHpEWLJD8/r5RYoXCKqYSqV5dWrvR2FSgv9PeN44knpJwc6amnpOzs3GGufwcOlJYulfzZMkriCAKAD3rySemllzyHxcRIf/874XAlAgKAT3r6aenFF3OfP/CA9N57UqVK3q2poiEgAPisyZNzb23917+kgABvV1PxEBAAACsCAgBgRUAAAKwICACAFQEBALAiIAAAVgQEAMCKgAAAWBEQAAArAgIAYEVAAACsCAgAgBUBAQCwIiAAAFYEBADAioAAAFgREAAAKwICAGBFQAAArAgIAIAVAQEAsCIgAABWBAQAwIqAAABYERAAACsCAgBgRUAAAKwICACAFQEBALAiIAAAVgQEAMCKgAAAWBEQAAArAgIAYEVAAACsCAgAgBUBAQCwIiAAAFYEBADAioAAAFgREAAAKwICAGBFQAAArAgIAIAVAQEAsCIgAABWBAQAwIqAAABYERAAACsCAgBgRUAAAKz8SzphWlqaqlatWpq1oILZu3evx7+4cdHXviMtLa3IbR3GGFOUhomJiUpMTFR2drb27dtX4uIAAN53+vRpBQcHF9imyAHhcubMGYWEhGj+/Plq06bNNRWIim3v3r0aPHiwFi9erGbNmnm7HJQh+tp3pKamauTIkUUKiBKfYmrSpIlat25d0slxHWnWrBl97SPo6xvf2bNni9yWi9QAACsCAgBgRUAAAKwICACAFQEBALAiIAAAVgQEAMCKgAAAWBEQAAArAgIAYEVAAACsCAgAgBUBAQCwIiAAAFYEBADAioAAAFgREAAAKwICAGBFQAAArAgIAIAVAQEAsCIgAABWBAQAwIqAAABYERAAACsCAgBgRUAAAKwICACAFQEBALAiIAAAVgQEAMCKgAAAWBEQAAArAgIAYEVAAACsCAgAgBUBAQCwIiAAAFYEBADAioAAAFgREAAAKwICAGBFQAAArAgIAIAVAQEAsCIgAABWBAQAn/HZZ5/J4XAU+fHOO+94u2SvIiAAAFb+3i4AALxh1KhRGj16dIFt6tevX07VVEwEBACfFBYWphYtWni7jAqNU0wAACsCAgBgRUCUUGamNH68lJ7u7UpQHuhv+CICooQGDZJmzpR69GCj4Qvob/giLlKXUGystHKltHt37kZj/XqpRg1vV4WyQn/feI4fP66vv/463/FhYWEKCwsrx4oqHo4gSig+XnrzTcnhyN1odO8uZWR4uyqUFfr7xjNnzhy1bNky38fs2bO9XaLXERDXYPhwaf78XzYaPXqw0biR0d/wNT4fEHPn5q7wJX089phkTO68du2SYmK8uzwoGP0Nlz//+c8yxuT7mDJlirdL9DqfD4jSduqUtytAeaK/cSPz+YvUcXFS164lnz4pSRo3Lnevsm5dafnyUisNZYD+BorO5wMiNDT3URLr1kmTJv2ysdiwQYqIKM3qUNrob6DoOMVUQuvXS/36SRcusLHwBfQ3fBEBUUJ/+hMbC19Cf8MXERAl9NFHUnQ0GwtfQX/DF/n8NYiSql4995u18A30N3wRRxAAACsCAgBgxSkmAD6ja9euMq6vwqNQHEEAAKwICACAFQEBALAiIAAAVgQEAMCKgAAAWBEQAAArAgIAYEVAAACsCAgAgBUBAQCwIiAAAFYEBADAioAAAFgREAAAKwICAGBFQAAArAgIAIAVAQEAsCIgAABWBAQAwIqAAABYERAAACsCAgBgRUAAAKwICACAFQEBALAiIAAAVgQEAMCKgAAAWBEQAAArAgIAYEVAAACsCAgAgBUBAQCwIiAAAFYEBADAioAAAFgREAAAKwICAGBFQAAArAgIAIAVAQEAsCIgAABWBAQAwIqAAABYERAAACsCAgBgRUAAAKwICACAFQEBALDyL+4ExhhJ0s6dO0u7FlQwaWlpkqTU1FSdPXvWy9WgLNHXvsO17XZtywviMEVpJSkxMVGJiYnKysrSgQMHrqlAAIB3HTlyRPXr1y+wTZEDwiUnJ0cRERFKTU2Vw+G4pgJR8bVt21Zbt271dhkoB/S1bzDGqE2bNtq3b5+czoKvMhT7FJPT6VRAQIBCQkJKXCCuH35+fgoODvZ2GSgH9LXvCAgIKDQcpBJepE5ISCjJZLgO0de+g772HUXt62KfYgIA+AZucwUAWBEQAAArAgIAYEVAAACsCAgAgBUBAQCwIiAAAFYEBADA6v8AmVrHlF2SlaoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the environment\n",
    "env = GridWorldEnv(grid_size=(3, 3), start=(0, 0), goal=(2, 2))\n",
    "\n",
    "# Plotting a random policy\n",
    "plot_grid_with_policy(env)\n",
    "\n",
    "# we get now the random initialized policy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
